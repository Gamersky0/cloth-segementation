{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.methods.groundtruth import GroundTruth # import GroundTruth OK\n",
    "from scripts.methods.model.model import ClothEdgeModel # import ClothEdgeModel OK\n",
    "from my_utils import *\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkGraspSelector:\n",
    "    \"\"\"\n",
    "    Grasp Selector using the output of the cloth region segmentation network\n",
    "    \"\"\"\n",
    "    def __init__(self, grasp_point_method, grasp_angle_method, grasp_target):\n",
    "        self.grasp_point_method = grasp_point_method\n",
    "        self.grasp_angle_method = grasp_angle_method\n",
    "        self.grasp_pt = None\n",
    "        self.grasp_target= grasp_target\n",
    "\n",
    "    # seems not used in this project\n",
    "    def sample_grasp(self, segmentation, pred):\n",
    "        \"\"\"Takes a 2D array prop to prob as input and sample grasp point.\"\"\"\n",
    "        # Filter for outer edge points w/o overlap only\n",
    "        im_height, im_width, _ = segmentation.shape\n",
    "        outer_edges_mask = np.zeros((im_height, im_width))\n",
    "        outer_edges_mask[segmentation[:,:,1]==255] = 1\n",
    "\n",
    "        var_map = outer_edges_mask*pred[:, :, -1]\n",
    "        pvec = var_map.ravel()/np.sum(var_map) # flatten and normalize to PMF\n",
    "        idx = np.random.choice(a=range(pvec.shape[0]), p=pvec)\n",
    "        y,x = np.unravel_index(idx, var_map.shape)\n",
    "\n",
    "        im = (var_map / var_map.max() * 255).astype(np.uint8)\n",
    "        self.pub.publish(self.bridge.cv2_to_imgmsg(im, encoding=\"mono8\"))\n",
    "\n",
    "        return np.array([y,x])\n",
    "\n",
    "    def select_grasp(self, rgb, corners, outer_edges, inner_edges, pred, retries=1, num_neighbour=8):\n",
    "        impred = np.zeros((corners.shape[0], corners.shape[1], 3), dtype=np.uint8)\n",
    "        impred[:, :, 0] += corners\n",
    "        impred[:, :, 1] += outer_edges\n",
    "        impred[:, :, 2] += inner_edges\n",
    "\n",
    "        idxs = np.where(corners == 255)\n",
    "        corners[:] = 1\n",
    "        corners[idxs] = 0\n",
    "        idxs = np.where(outer_edges == 255)\n",
    "        outer_edges[:] = 1\n",
    "        outer_edges[idxs] = 0\n",
    "        idxs = np.where(inner_edges == 255)\n",
    "        inner_edges[:] = 1\n",
    "        inner_edges[idxs] = 0\n",
    "\n",
    "        # Choose pixel in pred to grasp\n",
    "        grasp_target = self.grasp_target\n",
    "        channel = 1 if grasp_target == 'edges' else 0\n",
    "        indices = np.where(impred[:, :, channel] == 255) # outer_edge\n",
    "        if len(indices[0]) == 0:\n",
    "            print(\"No graspable pixels detected\")\n",
    "            return 0, 0, 0, 0, 0\n",
    "\n",
    "        if self.grasp_point_method == 'policy':\n",
    "            outer_edges = deepcopy(pred[:, :, 1])\n",
    "            mask = np.zeros_like(outer_edges)\n",
    "            mask[outer_edges > 0.9] = 1\n",
    "            var = deepcopy(pred[:, :, -1])\n",
    "            var *= mask\n",
    "\n",
    "            pvar = var.ravel()/np.sum(var) # flatten and normalize to PMF\n",
    "            idx = np.random.choice(a=range(pvar.shape[0]), p=pvar)\n",
    "            y, x = np.unravel_index(idx, var.shape)\n",
    "\n",
    "            # 好像没有用到var_map\n",
    "            var_map = (var / var.max() * 255.).astype('uint8')\n",
    "            # self.pub.publish(self.bridge.cv2_to_imgmsg(var_map))\n",
    "        else: \n",
    "            if self.grasp_point_method == 'manual':\n",
    "                # Only works once due to rendering issues, need to restart service\n",
    "                print(\"Manually choosing grasp point\")\n",
    "                wintitle = 'Choose grasp point'\n",
    "                cv2.namedWindow(wintitle)\n",
    "                cv2.setMouseCallback(wintitle, self.winclicked)\n",
    "                cv2.imshow(wintitle, impred)\n",
    "                cv2.waitKey(0)\n",
    "                y, x = self.grasp_pt\n",
    "            elif self.grasp_point_method == 'random':\n",
    "                idx = np.random.choice(range(len(indices[0])))\n",
    "                y = indices[0][idx]\n",
    "                x = indices[1][idx]\n",
    "            elif self.grasp_point_method == 'confidence':\n",
    "                # Filter out ambiguous points\n",
    "                # impred:[im_height, im_width, 3] -> corner, outer edge, inner edge predictions\n",
    "                segmentation = deepcopy(impred)\n",
    "                im_height, im_width, _ = segmentation.shape\n",
    "                segmentation[np.logical_and(impred[:,:,1]==255, impred[:,:,2]==255),2] = 0\n",
    "                segmentation[np.logical_and(impred[:,:,1]==255, impred[:,:,2]==255),1] = 0\n",
    "\n",
    "                inner_edges_filt = np.ones((im_height, im_width))\n",
    "                inner_edges_filt[segmentation[:,:,2]==255] = 0\n",
    "\n",
    "                outer_edges_filt = np.ones((im_height, im_width))\n",
    "                outer_edges_filt[segmentation[:,:,1]==255] = 0\n",
    "\n",
    "                # Get outer-inner edge correspondence\n",
    "                xx, yy =  np.meshgrid([x for x in range(im_width)],\n",
    "                                    [y for y in range(im_height)])\n",
    "\n",
    "                if grasp_target == 'edges':\n",
    "                    xx_o = xx[segmentation[:,:,1]==255]\n",
    "                    yy_o = yy[segmentation[:,:,1]==255]\n",
    "                else:\n",
    "                    xx_o = xx[segmentation[:,:,0]==255]\n",
    "                    yy_o = yy[segmentation[:,:,0]==255]\n",
    "\n",
    "                xx_i = xx[segmentation[:,:,2]==255]\n",
    "                yy_i = yy[segmentation[:,:,2]==255]\n",
    "\n",
    "                _, lbl = cv2.distanceTransformWithLabels(inner_edges_filt.astype(np.uint8), cv2.DIST_L2, 5, labelType=cv2.DIST_LABEL_PIXEL)\n",
    "\n",
    "                loc = np.where(inner_edges_filt==0)\n",
    "                xx_inner = loc[1]\n",
    "                yy_inner = loc[0]\n",
    "                label_to_loc = [[0,0]]\n",
    "\n",
    "                for j in range(len(yy_inner)):\n",
    "                    label_to_loc.append([yy_inner[j],xx_inner[j]])\n",
    "\n",
    "                label_to_loc = np.array(label_to_loc)\n",
    "                direction = label_to_loc[lbl]\n",
    "                # Calculate distance to the closest inner edge point for every pixel in the image\n",
    "                distance = np.zeros(direction.shape)\n",
    "\n",
    "                distance[:,:,0] = np.abs(direction[:,:,0]-yy)\n",
    "                distance[:,:,1] = np.abs(direction[:,:,1]-xx)\n",
    "                \n",
    "                # Normalize distance vectors\n",
    "                mag = np.linalg.norm([distance[:,:,0],distance[:,:,1]],axis = 0)+0.00001\n",
    "                distance[:,:,0] = distance[:,:,0]/mag\n",
    "                distance[:,:,1] = distance[:,:,1]/mag\n",
    "\n",
    "                # Get distances of outer edges\n",
    "                distance_o = distance[segmentation[:,:,1]==255,:]\n",
    "\n",
    "                # Get outer edge neighbors of each outer edge point\n",
    "                num_neighbour = 100\n",
    "\n",
    "                # For every outer edge point, find its closest K neighbours \n",
    "                tree = KDTree(np.vstack([xx_o,yy_o]).T, leaf_size=2)\n",
    "                dist, ind = tree.query(np.vstack([xx_o,yy_o]).T, k=num_neighbour)\n",
    "                \n",
    "                xx_neighbours = distance_o[ind][:,:,1]\n",
    "                yy_neighbours = distance_o[ind][:,:,0]\n",
    "                xx_var = np.var(xx_neighbours,axis = 1)\n",
    "                yy_var = np.var(yy_neighbours,axis = 1)\n",
    "                var = xx_var+yy_var\n",
    "                var = (var-np.min(var))/(np.max(var)-np.min(var))\n",
    "                \n",
    "                # Choose min var point\n",
    "                var_min = np.min(var)\n",
    "                min_idxs = np.where(var == var_min)[0]\n",
    "                print(\"Number of min var indices:\", len(min_idxs))\n",
    "                idx = np.random.choice(min_idxs)\n",
    "                x = xx_o[idx]\n",
    "                y = yy_o[idx]\n",
    "\n",
    "                # myplot(impred, xx_o, yy_o, var, outer_edges_filt, xx, yy, segmentation)\n",
    "                ENABLE_PLOT = True\n",
    "                if ENABLE_PLOT:\n",
    "                    impred2 = deepcopy(segmentation)\n",
    "                    impred2[:, :, 0] = 0 # 将第一个维度全部设为0\n",
    "                    fig = plt.figure()\n",
    "                    ax = plt.subplot(121)\n",
    "                    empty = np.zeros(impred.shape)\n",
    "                    ax.imshow(empty) # 将empty显示在第一个子图中,这里呈现一个白色的矩形\n",
    "                    scat = ax.scatter(xx_o, yy_o, c=var, cmap='RdBu', s=3)\n",
    "                    # scat = ax.scatter(xx_i, yy_i, c=var, cmap='RdBu', s=3)\n",
    "                    plt.colorbar(scat)\n",
    "                    ax.scatter(x, y, c='blue', alpha=0.7)\n",
    "                    ax = plt.subplot(122)\n",
    "                    ax.imshow(impred2)\n",
    "                    # plt.show()\n",
    "                    \n",
    "                    # for arrow plot\n",
    "                    # factor = 2\n",
    "                    # xx = xx[outer_edges_filt==0]\n",
    "                    # yy = yy[outer_edges_filt==0]\n",
    "                    # direction_o = direction[segmentation[:,:,1]==255,:]\n",
    "                    # ax.quiver(xx_o[::factor],yy_o[::factor],direction_o[::factor,1]-xx_o[::factor],-direction_o[::factor,0]+yy_o[::factor], color='white', scale=1, scale_units='x')\n",
    "\n",
    "                    base_path = \"/home/chimy/projects/biyesheji/cloth-segmentation/service_without_ROS_test/grasp_output\"\n",
    "                    tstamp = datetime.now().strftime(\"%d_%m_%Y_%H:%M:%S\")\n",
    "                    tstamp_path = os.path.join(base_path, tstamp)\n",
    "                    os.makedirs(tstamp_path)\n",
    "\n",
    "                    fig.canvas.draw()\n",
    "                    w,h = fig.canvas.get_width_height()\n",
    "                    buf = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(h, w, 3)\n",
    "                    np.save(os.path.join(tstamp_path, \"plot_%s\" % tstamp), buf)\n",
    "                    \n",
    "                    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "                    cv2.imwrite(os.path.join(tstamp_path, \"rgb_%s.png\" % tstamp), rgb)\n",
    "                    plt.savefig(os.path.join(tstamp_path, 'uncertainty_%s.png' % tstamp))\n",
    "                    plt.show()\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        print(\"Grasp point method: \", self.grasp_point_method)\n",
    "        print(\"Choose pixel x:\", x, \"y:\", y)\n",
    "\n",
    "        # Get outer_pt and inner_pt for computing grasp angle\n",
    "        if self.grasp_angle_method == 'inneredge':\n",
    "            # 计算内边缘到当前像素点的最短距离,并返回距离最近的inner_edge的像素坐标\n",
    "            \n",
    "            # 返回两个矩阵,temp记录每个像素点到离他最近的inner_edge的距离, lbl记录每个像素点距离最近的边缘的标记值\n",
    "            temp, lbl = cv2.distanceTransformWithLabels(inner_edges.astype(np.uint8), cv2.DIST_L2, 5, labelType=cv2.DIST_LABEL_PIXEL)\n",
    "            # 获取所有inner_edges==0的x和y值\n",
    "            loc = np.where(inner_edges==0)\n",
    "            xx_inner = loc[1]\n",
    "            yy_inner = loc[0]\n",
    "\n",
    "            # change\n",
    "            label_to_loc = list(zip(yy_inner, xx_inner))\n",
    "            # label_to_loc = zip(yy_inner, xx_inner) # AttributeError: 'zip' object has no attribute 'insert'\n",
    "            label_to_loc.insert(0, (0, 0)) # 1-indexed\n",
    "\n",
    "            label_to_loc = np.array(label_to_loc)\n",
    "            direction = label_to_loc[lbl]\n",
    "            outer_pt = np.array([y, x])\n",
    "            inner_pt = direction[y, x]\n",
    "        elif self.grasp_angle_method == 'center': # 貌似outer_pt是随机生成的,inner_pt是由物体的包围框计算,可以看作物体的几何中心\n",
    "            # 随机抽取一个像素作为抓取点的位置\n",
    "            idx = np.random.choice(range(len(indices[0])))\n",
    "            y = indices[0][idx]\n",
    "            x = indices[1][idx]\n",
    "\n",
    "            # get bbox\n",
    "            bbox = deepcopy(outer_edges) if grasp_target == 'edges' else deepcopy(corners)\n",
    "            \n",
    "            # idxs提取掩码中非0像素点,生成一个全0的空白掩码,将idxs对应的坐标位置的像素值赋1,（将物体从边缘或者角点的形状转换成矩形）\n",
    "            idxs = np.where(bbox == 0)\n",
    "            bbox[:] = 0\n",
    "            bbox[idxs] = 1\n",
    "\n",
    "            # 计算bbox的尺寸和位置\n",
    "            pbox = cv2.boundingRect(bbox)\n",
    "            center_x = pbox[0] + 0.5*pbox[2]\n",
    "            center_y = pbox[1] + 0.5*pbox[3]\n",
    "            outer_pt = np.array([y, x])\n",
    "            inner_pt = np.array([center_y, center_x])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # count the angle\n",
    "        v = inner_pt - outer_pt\n",
    "        magn = np.linalg.norm(v)\n",
    "\n",
    "        if magn == 0:\n",
    "            error_msg = \"magnitude is zero for %d samples\" % retries\n",
    "            print(error_msg)\n",
    "\n",
    "        unitv = v / magn\n",
    "        originv = [0, 1] # [y, x]\n",
    "        angle = np.arccos(np.dot(unitv, originv))\n",
    "\n",
    "        if v[0] < 0:\n",
    "            angle = -angle\n",
    "        \n",
    "        return outer_pt[0], outer_pt[1], angle, inner_pt[0], inner_pt[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDetector:\n",
    "    def __init__(self, detection_method, crop_dims, datapath):\n",
    "        self.detection_method = detection_method\n",
    "        self.datapath = datapath\n",
    "        self._init_model(crop_dims)\n",
    "        self.depth_im = None\n",
    "        self.rgb_im = None\n",
    "        print(\"finish init\")\n",
    "\n",
    "    def _init_model(self, crop_dims):\n",
    "        if self.detection_method == 'groundtruth':\n",
    "            self.crop_dims = crop_dims\n",
    "            self.model = GroundTruth(self.crop_dims)\n",
    "        elif self.detection_method == 'network':\n",
    "            self.crop_dims = crop_dims\n",
    "            grasp_angle_method = 'inneredge'\n",
    "            \n",
    "            # grasp_angle_method 表示程序在计算抓取角度时要使用的方法\n",
    "            # 如果 grasp_angle_method 为 'predict'，说明程序要使用的模型是用于预测抓取角度的模型，\n",
    "            # 因此 model_path 参数将被替换为 model_angle_path 参数，即程序将使用不同的模型。\n",
    "            # 否则，model_path 参数保持不变，程序将使用默认的模型。\n",
    "            # 因此，这行代码的作用是根据 grasp_angle_method 的值获取正确的模型路径，并将其保存在 model_path 变量中。\n",
    "            \n",
    "            model_path = \"/home/chimy/old_projects/cloth-segmentation-main/runspath/pretrained_weights\"\n",
    "            self.model = ClothEdgeModel(self.crop_dims, grasp_angle_method, model_path)\n",
    "\n",
    "    def detect_edge(self, i):\n",
    "        try:\n",
    "            rgb_im = Image.open(os.path.join(self.datapath, \"rgb_%d.png\" % i))\n",
    "            depth_im = np.load(os.path.join(self.datapath, \"%d_depth.npy\" % i))\n",
    "            max_d = np.nanmax(depth_im)\n",
    "            depth_im[np.isnan(depth_im)] = max_d\n",
    "            print(os.path.join(self.datapath, \"%d_depth.npy\" % i))\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found\")\n",
    "        except:\n",
    "            print(\"Failed to read file\")\n",
    "        \n",
    "        # Prevents NaN from causing errors in image processing\n",
    "        self.depth_im = np.nan_to_num(depth_im)\n",
    "        self.rgb_im = cv2.imread(os.path.join(self.datapath, \"rgb_%d.png\" % i))\n",
    "\n",
    "        # _server_cb content\n",
    "        print(\"Received cloth detection request\")\n",
    "\n",
    "        rgb_im = deepcopy(self.rgb_im)  \n",
    "        depth_im = deepcopy(self.depth_im)\n",
    "\n",
    "        # plt.figure(dpi=300)\n",
    "        # plt.subplot(121)\n",
    "        # plt.title(\"rgb_im\")\n",
    "        # plt.imshow(rgb_im)\n",
    "        # plt.axis(\"off\")\n",
    "        # plt.subplot(122)\n",
    "        # plt.title(\"depth_im\")\n",
    "        # plt.imshow(depth_im)\n",
    "        # plt.axis(\"off\")\n",
    "        # plt.show()\n",
    "\n",
    "        response = DetectEdgeResponse()\n",
    "        response.rgb_im = self.rgb_im\n",
    "        response.depth_im = self.depth_im\n",
    "        # get response and save images\n",
    "        if self.detection_method == 'groundtruth':\n",
    "            pred = self.model.predict(rgb_im)\n",
    "            # pred = self.model.predict(rgb_im)\n",
    "            response.prediction = pred\n",
    "        elif self.detection_method == 'network':\n",
    "            self.model.update() # Check if model needs to be reloaded\n",
    "            print(\"depth_image.shape: \", depth_im.shape)\n",
    "            # all numpy.ndarray\n",
    "            corners, outer_edges, inner_edges, pred = self.model.predict(depth_im)\n",
    "            print(\"add time later\")\n",
    "            print(\"corners.shape:\", corners.shape)\n",
    "            print(\"outer_edges.shape:\", outer_edges.shape)\n",
    "            print(\"inner_edges.shape:\",inner_edges.shape)\n",
    "            print(\"pred.shape:\",pred.shape)\n",
    "\n",
    "            # save prediction \n",
    "            corners_img = get_depth_img(corners)\n",
    "            cv2.imwrite('corners_img.png', corners_img)\n",
    "            outer_img = get_depth_img(outer_edges)\n",
    "            cv2.imwrite('outer_img.png', outer_img)\n",
    "            inner_img = get_depth_img(inner_edges)\n",
    "            cv2.imwrite('inner_img.png', inner_img)\n",
    "            pred_img = get_depth_img(pred)\n",
    "            cv2.imwrite('pred_img.png', pred_img)\n",
    "\n",
    "        response.prediction = pred\n",
    "        response.corners = corners\n",
    "        response.outer_edges = outer_edges\n",
    "        response.inner_edges = inner_edges\n",
    "        \n",
    "        # TYPE_TEST = True\n",
    "        # if TYPE_TEST:\n",
    "        #     print(\"response.prediction.type:\",response.prediction.type)\n",
    "        #     print(\"response.corners.type:\",response.corners.type)\n",
    "        #     print(\"response.outer_edges.type:\",response.outer_edges.type)\n",
    "        #     print(\"response.inner_edges.type:\",response.inner_edges.type)\n",
    "        return response\n",
    "\n",
    "    def run(self, img_index):\n",
    "        # set self.depth_im & self.rgb_im, \n",
    "        # img_index: dataset image index\n",
    "        index = img_index\n",
    "\n",
    "        # DetectEdgeResponse\n",
    "        prediction = self.detect_edge(index)\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraspSelector:\n",
    "    def __init__(self, detection_method, grasp_point_method, grasp_angle_method, img_prediction, grasp_target):\n",
    "        self.detection_method = detection_method\n",
    "        self.grasp_point_method = grasp_point_method\n",
    "        self.grasp_angle_method = grasp_angle_method\n",
    "        self.img_prediction = img_prediction\n",
    "        self.grasp_target = grasp_target\n",
    "        self._init_selector()\n",
    "\n",
    "    def _init_selector(self):\n",
    "        # self.selector = XXX\n",
    "        if self.detection_method == 'groundtruth':\n",
    "            print(\"Not define GroundTruthSelector\")\n",
    "            # self.selector = GroundTruthSelector()\n",
    "        elif self.detection_method == 'network':\n",
    "            self.selector = NetworkGraspSelector(self.grasp_point_method, self.grasp_angle_method, self.grasp_target)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        print(\"Success init selector.\")\n",
    "        return\n",
    "    \n",
    "    def run(self):\n",
    "        img_prediction = self.img_prediction\n",
    "        inner_py = None\n",
    "        inner_px = None\n",
    "\n",
    "        if self.detection_method == 'groundtruth':\n",
    "            pred = deepcopy(img_prediction.prediction)\n",
    "            py, px, angle, inner_py, inner_px, var, angle_x, angle_y = self.selector.select_grasp(pred)\n",
    "        elif self.detection_method == 'network':\n",
    "            corners = deepcopy(img_prediction.corners)\n",
    "            outer_edges = deepcopy(img_prediction.outer_edges)\n",
    "            inner_edges = deepcopy(img_prediction.inner_edges)\n",
    "            rgb = deepcopy(img_prediction.rgb_im)\n",
    "            pred = deepcopy(img_prediction.prediction)\n",
    "            py, px, angle, inner_py, inner_px = self.selector.select_grasp(rgb, corners, outer_edges, inner_edges, pred)\n",
    "        else:\n",
    "            prediction = deepcopy(img_prediction.prediction)\n",
    "            py, px, angle = self.selector.select_grasp(prediction)\n",
    "            print(py, px, angle)\n",
    "\n",
    "        response = SelectGraspResponse()\n",
    "        response.py = py\n",
    "        response.px = px\n",
    "        response.angle = angle\n",
    "        # print inner_px & inner_py\n",
    "        if inner_py != None and inner_px != None:\n",
    "            response.inner_py = inner_py\n",
    "            response.inner_px = inner_px\n",
    "        if self.detection_method == 'groundtruth' and px != 0:\n",
    "            response.var = var.flatten()\n",
    "            response.angle_x = angle_x.flatten()\n",
    "            response.angle_y = angle_y.flatten()\n",
    "\n",
    "        print(\"Get grasp selection response:\")\n",
    "        print('{:<10} {:<5} {:<10} {:<5}'.format(\"px:\", px, \"py:\", py))\n",
    "        print('\\033[32m' + '{:<10} {} '.format(\"angle:\", angle) + '\\033[0m')\n",
    "        print('{:<10} {:<5} {:<10} {:<5}'.format(\"inner_px:\", inner_px, \"inner_py:\", inner_py))\n",
    "\n",
    "        # self.selector.plot(pred, px, py, var, None, inner_px, inner_py, prediction.prediction)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m==========================================\u001b[0m\n",
      "\u001b[32mBegin detect_edge process\u001b[0m\n",
      "finish init\n",
      "/home/chimy/projects/biyesheji/data_painted_towel/10_depth.npy\n",
      "Received cloth detection request\n",
      "depth_image.shape:  (255, 243)\n",
      "In model.predict process, at first, image.shape:  (255, 243)\n",
      "In model.predict process, after crop, image.shape:  (255, 243)\n",
      "add time later\n",
      "corners.shape: (255, 243)\n",
      "outer_edges.shape: (255, 243)\n",
      "inner_edges.shape: (255, 243)\n",
      "pred.shape: (255, 243, 3)\n",
      "\u001b[32mEnd detect_edge process\u001b[0m\n",
      "\u001b[32m==========================================\u001b[0m\n",
      "prediction.rgb_im.shape:  (255, 243, 3)\n",
      "prediction.depth_im.shape: (255, 243)\n",
      "prediction.prediction.shape: (255, 243, 3)\n",
      "prediction.corners.shape: (255, 243)\n",
      "prediction.outer_edges.shape: (255, 243)\n",
      "prediction.inner_edges.shape: (255, 243)\n",
      "\u001b[32m==========================================\u001b[0m\n",
      "\u001b[32mBegin select_grasp process\u001b[0m\n",
      "Success init selector.\n",
      "Number of min var indices: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 703 elements, which is inconsistent with 'x' and 'y' with size 1787.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4290\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4291\u001b[0;31m                 \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4292\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid RGBA argument: {orig_c!r}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: 0.1671255177071298",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24082/3664022901.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[32m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'=========================================='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[32m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Begin select_grasp process'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mgrasp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_grasp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[32m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'End select_grasp process'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[32m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'=========================================='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24082/3664022901.py\u001b[0m in \u001b[0;36mselect_grasp\u001b[0;34m(prediction)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraspSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrasp_point_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrasp_angle_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrasp_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mgrasp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrasp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24082/359349001.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_px\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_grasp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouter_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24082/1736972088.py\u001b[0m in \u001b[0;36mselect_grasp\u001b[0;34m(self, rgb, corners, outer_edges, inner_edges, pred, retries, num_neighbour)\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 将empty显示在第一个子图中,这里呈现一个白色的矩形\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                     \u001b[0mscat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RdBu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0mscat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RdBu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 **kwargs)\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4451\u001b[0m             self._parse_scatter_color_args(\n\u001b[1;32m   4452\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4453\u001b[0;31m                 get_next_color_func=self._get_patches_for_fill.get_next_color)\n\u001b[0m\u001b[1;32m   4454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4455\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplotnonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/towel37/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4295\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4296\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4297\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0minvalid_shape_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxsize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4298\u001b[0m                     \u001b[0;31m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m                     \u001b[0;31m# severe failure => one may appreciate a verbose feedback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 703 elements, which is inconsistent with 'x' and 'y' with size 1787."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def detect_edge():\n",
    "    detection_method = 'network'\n",
    "    datapath = \"/home/chimy/projects/biyesheji/data_painted_towel\"\n",
    "    crop_dims = [180, 650, 450, 900, 2] # seems not used yet\n",
    "    img_index = 10\n",
    "\n",
    "    e = EdgeDetector(detection_method, crop_dims, datapath)\n",
    "    prediction = e.run(img_index)\n",
    "    return prediction\n",
    "\n",
    "def select_grasp(prediction):\n",
    "    detection_method = \"network\"\n",
    "    # Option: random, manual, confidence, policy\n",
    "    grasp_point_method = \"confidence\"\n",
    "    # Option: predict没有写?, inneredge, center\n",
    "    grasp_angle_method = \"inneredge\"\n",
    "    # Option: corner, edge\n",
    "    grasp_target = \"edge\"\n",
    "\n",
    "    g = GraspSelector(detection_method, grasp_point_method, grasp_angle_method, prediction, grasp_target)\n",
    "    grasp = g.run()\n",
    "    return grasp\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('\\033[32m' + '==========================================' + '\\033[0m')\n",
    "    print('\\033[32m' + 'Begin detect_edge process' + '\\033[0m')\n",
    "    prediction = detect_edge()\n",
    "    print('\\033[32m' + 'End detect_edge process' + '\\033[0m')\n",
    "    print('\\033[32m' + '==========================================' + '\\033[0m')\n",
    "\n",
    "    # print prediction shape \n",
    "    ENBALE_PREDICTION_SHAPE_TEST = True\n",
    "    if ENBALE_PREDICTION_SHAPE_TEST:\n",
    "        print('{:<25} {}'.format(\"prediction.rgb_im.shape:\", prediction.rgb_im.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.depth_im.shape:\", prediction.depth_im.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.prediction.shape:\", prediction.prediction.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.corners.shape:\", prediction.corners.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.outer_edges.shape:\", prediction.outer_edges.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.inner_edges.shape:\", prediction.inner_edges.shape))\n",
    "\n",
    "    print('\\033[32m' + '==========================================' + '\\033[0m')\n",
    "    print('\\033[32m' + 'Begin select_grasp process' + '\\033[0m')\n",
    "    grasp = select_grasp(prediction)\n",
    "    print('\\033[32m' + 'End select_grasp process' + '\\033[0m')\n",
    "    print('\\033[32m' + '==========================================' + '\\033[0m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "towel37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
