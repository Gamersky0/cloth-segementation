{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.methods.groundtruth import GroundTruth # import GroundTruth OK\n",
    "from scripts.methods.model.model import ClothEdgeModel # import ClothEdgeModel OK\n",
    "from my_utils import *\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkGraspSelector:\n",
    "    \"\"\"Grasp Selector using the output of the cloth region segmentation network\n",
    "    \"\"\"\n",
    "    def __init__(self, grasp_point_method, grasp_angle_method, grasp_target):\n",
    "        self.grasp_point_method = grasp_point_method\n",
    "        self.grasp_angle_method = grasp_angle_method\n",
    "        self.grasp_pt = None\n",
    "        self.grasp_target= grasp_target\n",
    "\n",
    "    # seems not used in this project\n",
    "    def sample_grasp(self, segmentation, pred):\n",
    "        \"\"\"Takes a 2D array prop to prob as input and sample grasp point.\"\"\"\n",
    "        # Filter for outer edge points w/o overlap only\n",
    "        im_height, im_width, _ = segmentation.shape\n",
    "        outer_edges_mask = np.zeros((im_height, im_width))\n",
    "        outer_edges_mask[segmentation[:,:,1]==255] = 1\n",
    "\n",
    "        var_map = outer_edges_mask*pred[:, :, -1]\n",
    "        pvec = var_map.ravel()/np.sum(var_map) # flatten and normalize to PMF\n",
    "        idx = np.random.choice(a=range(pvec.shape[0]), p=pvec)\n",
    "        y,x = np.unravel_index(idx, var_map.shape)\n",
    "\n",
    "        im = (var_map / var_map.max() * 255).astype(np.uint8)\n",
    "        self.pub.publish(self.bridge.cv2_to_imgmsg(im, encoding=\"mono8\"))\n",
    "\n",
    "        return np.array([y,x])\n",
    "\n",
    "    def select_grasp(self, rgb, corners, outer_edges, inner_edges, pred, retries=1, num_neighbour=8):\n",
    "        impred = np.zeros((corners.shape[0], corners.shape[1], 3), dtype=np.uint8)\n",
    "        impred[:, :, 0] += corners\n",
    "        impred[:, :, 1] += outer_edges\n",
    "        impred[:, :, 2] += inner_edges\n",
    "\n",
    "        idxs = np.where(corners == 255)\n",
    "        corners[:] = 1\n",
    "        corners[idxs] = 0\n",
    "        idxs = np.where(outer_edges == 255)\n",
    "        outer_edges[:] = 1\n",
    "        outer_edges[idxs] = 0\n",
    "        idxs = np.where(inner_edges == 255)\n",
    "        inner_edges[:] = 1\n",
    "        inner_edges[idxs] = 0\n",
    "\n",
    "        # Choose pixel in pred to grasp\n",
    "        grasp_target = self.grasp_target\n",
    "        channel = 1 if grasp_target == 'edges' else 0\n",
    "        indices = np.where(impred[:, :, channel] == 255) # outer_edge\n",
    "        if len(indices[0]) == 0:\n",
    "            print(\"No graspable pixels detected\")\n",
    "            return 0, 0, 0, 0, 0\n",
    "\n",
    "        if self.grasp_point_method == 'policy':\n",
    "            outer_edges = deepcopy(pred[:, :, 1])\n",
    "            mask = np.zeros_like(outer_edges)\n",
    "            mask[outer_edges > 0.9] = 1\n",
    "            var = deepcopy(pred[:, :, -1])\n",
    "            var *= mask\n",
    "\n",
    "            pvar = var.ravel()/np.sum(var) # flatten and normalize to PMF\n",
    "            idx = np.random.choice(a=range(pvar.shape[0]), p=pvar)\n",
    "            y, x = np.unravel_index(idx, var.shape)\n",
    "\n",
    "            # 好像没有用到var_map\n",
    "            var_map = (var / var.max() * 255.).astype('uint8')\n",
    "            # self.pub.publish(self.bridge.cv2_to_imgmsg(var_map))\n",
    "        else: \n",
    "            if self.grasp_point_method == 'manual':\n",
    "                # Only works once due to rendering issues, need to restart service\n",
    "                print(\"Manually choosing grasp point\")\n",
    "                wintitle = 'Choose grasp point'\n",
    "                cv2.namedWindow(wintitle)\n",
    "                cv2.setMouseCallback(wintitle, self.winclicked)\n",
    "                cv2.imshow(wintitle, impred)\n",
    "                cv2.waitKey(0)\n",
    "                y, x = self.grasp_pt\n",
    "            elif self.grasp_point_method == 'random':\n",
    "                idx = np.random.choice(range(len(indices[0])))\n",
    "                y = indices[0][idx]\n",
    "                x = indices[1][idx]\n",
    "            elif self.grasp_point_method == 'confidence':\n",
    "                # Filter out ambiguous points\n",
    "                # impred:[im_height, im_width, 3] -> corner, outer edge, inner edge predictions\n",
    "                segmentation = deepcopy(impred)\n",
    "                im_height, im_width, _ = segmentation.shape\n",
    "                segmentation[np.logical_and(impred[:,:,1]==255, impred[:,:,2]==255),2] = 0\n",
    "                segmentation[np.logical_and(impred[:,:,1]==255, impred[:,:,2]==255),1] = 0\n",
    "\n",
    "                inner_edges_filt = np.ones((im_height, im_width))\n",
    "\n",
    "                inner_edges_filt[segmentation[:,:,2]==255] = 0\n",
    "\n",
    "                # Get outer-inner edge correspondence\n",
    "                xx, yy =  np.meshgrid([x for x in range(im_width)],\n",
    "                                    [y for y in range(im_height)])\n",
    "\n",
    "                if grasp_target == 'edges':\n",
    "                    xx_o = xx[segmentation[:,:,1]==255]\n",
    "                    yy_o = yy[segmentation[:,:,1]==255]\n",
    "                else:\n",
    "                    xx_o = xx[segmentation[:,:,0]==255]\n",
    "                    yy_o = yy[segmentation[:,:,0]==255]\n",
    "\n",
    "                xx_i = xx[segmentation[:,:,2]==255]\n",
    "                yy_i = yy[segmentation[:,:,2]==255]\n",
    "\n",
    "                _, lbl = cv2.distanceTransformWithLabels(inner_edges_filt.astype(np.uint8), cv2.DIST_L2, 5, labelType=cv2.DIST_LABEL_PIXEL)\n",
    "\n",
    "                loc = np.where(inner_edges_filt==0)\n",
    "                xx_inner = loc[1]\n",
    "                yy_inner = loc[0]\n",
    "                label_to_loc = [[0,0]]\n",
    "\n",
    "                for j in range(len(yy_inner)):\n",
    "                    label_to_loc.append([yy_inner[j],xx_inner[j]])\n",
    "\n",
    "                label_to_loc = np.array(label_to_loc)\n",
    "                direction = label_to_loc[lbl]\n",
    "                # Calculate distance to the closest inner edge point for every pixel in the image\n",
    "                distance = np.zeros(direction.shape)\n",
    "\n",
    "                distance[:,:,0] = np.abs(direction[:,:,0]-yy)\n",
    "                distance[:,:,1] = np.abs(direction[:,:,1]-xx)\n",
    "                \n",
    "                # Normalize distance vectors\n",
    "                mag = np.linalg.norm([distance[:,:,0],distance[:,:,1]],axis = 0)+0.00001\n",
    "                distance[:,:,0] = distance[:,:,0]/mag\n",
    "                distance[:,:,1] = distance[:,:,1]/mag\n",
    "\n",
    "                # Get distances of outer edges\n",
    "                distance_o = distance[segmentation[:,:,1]==255,:]\n",
    "\n",
    "                # Get outer edge neighbors of each outer edge point\n",
    "                num_neighbour = 100\n",
    "\n",
    "                # For every outer edge point, find its closest K neighbours \n",
    "                tree = KDTree(np.vstack([xx_o,yy_o]).T, leaf_size=2)\n",
    "                dist, ind = tree.query(np.vstack([xx_o,yy_o]).T, k=num_neighbour)\n",
    "                \n",
    "                xx_neighbours = distance_o[ind][:,:,1]\n",
    "                yy_neighbours = distance_o[ind][:,:,0]\n",
    "                xx_var = np.var(xx_neighbours,axis = 1)\n",
    "                yy_var = np.var(yy_neighbours,axis = 1)\n",
    "                var = xx_var+yy_var\n",
    "                var = (var-np.min(var))/(np.max(var)-np.min(var))\n",
    "                \n",
    "                # Choose min var point\n",
    "                var_min = np.min(var)\n",
    "                min_idxs = np.where(var == var_min)[0]\n",
    "                print(\"Number of min var indices:\", len(min_idxs))\n",
    "                idx = np.random.choice(min_idxs)\n",
    "                x = xx_o[idx]\n",
    "                y = yy_o[idx]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        print(\"Grasp point method:\", self.grasp_point_method, \". Choose pixel x:\", x, \"y:\", y)\n",
    "\n",
    "        # Get outer_pt and inner_pt for computing grasp angle\n",
    "        if self.grasp_angle_method == 'inneredge':\n",
    "            temp, lbl = cv2.distanceTransformWithLabels(inner_edges.astype(np.uint8), cv2.DIST_L2, 5, labelType=cv2.DIST_LABEL_PIXEL)\n",
    "            loc = np.where(inner_edges==0)\n",
    "            xx_inner = loc[1]\n",
    "            yy_inner = loc[0]\n",
    "            label_to_loc = zip(yy_inner, xx_inner) # 可能出现问题\n",
    "            label_to_loc.insert(0, (0, 0)) # 1-indexed\n",
    "            label_to_loc = np.array(label_to_loc)\n",
    "            direction = label_to_loc[lbl]\n",
    "            outer_pt = np.array([y, x])\n",
    "            inner_pt = direction[y, x]\n",
    "        \n",
    "        elif self.grasp_angle_method == 'center': # 貌似outer_pt是随机生成的,inner_pt是由物体的包围框计算,可以看作物体的几何中心\n",
    "            # 随机抽取一个像素作为抓取点的位置\n",
    "            idx = np.random.choice(range(len(indices[0])))\n",
    "            y = indices[0][idx]\n",
    "            x = indices[1][idx]\n",
    "\n",
    "            # get bbox\n",
    "            bbox = deepcopy(outer_edges) if grasp_target == 'edges' else deepcopy(corners)\n",
    "            \n",
    "            # idxs提取掩码中非0像素点,生成一个全0的空白掩码,将idxs对应的坐标位置的像素值赋1,（将物体从边缘或者角点的形状转换成矩形）\n",
    "            idxs = np.where(bbox == 0)\n",
    "            bbox[:] = 0\n",
    "            bbox[idxs] = 1\n",
    "\n",
    "            # 计算bbox的尺寸和位置\n",
    "            pbox = cv2.boundingRect(bbox)\n",
    "            center_x = pbox[0] + 0.5*pbox[2]\n",
    "            center_y = pbox[1] + 0.5*pbox[3]\n",
    "            outer_pt = np.array([y, x])\n",
    "            inner_pt = np.array([center_y, center_x])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # count the angle\n",
    "        v = inner_pt - outer_pt\n",
    "        magn = np.linalg.norm(v)\n",
    "\n",
    "        if magn == 0:\n",
    "            error_msg = \"magnitude is zero for %d samples\" % retries\n",
    "            print(error_msg)\n",
    "            # if rospy.get_param('break_on_error'):\n",
    "            #     raise rospy.ServiceException(error_msg)\n",
    "            # else:\n",
    "            #     rospy.logerr(error_msg)\n",
    "            #     magn = 1.0\n",
    "\n",
    "        unitv = v / magn\n",
    "        originv = [0, 1] # [y, x]\n",
    "        angle = np.arccos(np.dot(unitv, originv))\n",
    "\n",
    "        if v[0] < 0:\n",
    "            angle = -angle\n",
    "\n",
    "        # self.selector.plot(pred, px, py, var, None, inner_px, inner_py, prediction.prediction)\n",
    "        # self.plot(pred, xx_o, yy_o, var, inner_edges_filt, xx, yy, segmentation)\n",
    "\n",
    "        return outer_pt[0], outer_pt[1], angle, inner_pt[0], inner_pt[1]\n",
    "\n",
    "    def plot(impred, xx_o, yy_o, var, outer_edges_filt, xx, yy, segmentation):\n",
    "        \"\"\"\n",
    "        Plot for debugging\n",
    "        \"\"\"\n",
    "        impred2 = deepcopy(segmentation)\n",
    "        impred2[:, :, 0] = 0\n",
    "        fig = plt.figure()\n",
    "        ax = plt.subplot(121)\n",
    "        empty = np.zeros(impred.shape)\n",
    "        ax.imshow(empty)\n",
    "        scat = ax.scatter(xx_o, yy_o, c=var, cmap='RdBu', s=3)\n",
    "        plt.colorbar(scat)\n",
    "        ax.scatter(x, y, c='blue', alpha=0.7)\n",
    "        ax = plt.subplot(122)\n",
    "        ax.imshow(impred2)\n",
    "        \n",
    "        # arrow\n",
    "        # factor = 2\n",
    "        # xx = xx[outer_edges_filt==0]\n",
    "        # yy = yy[outer_edges_filt==0]\n",
    "        # direction_o = direction[segmentation[:,:,1]==255,:]\n",
    "        # ax.quiver(xx_o[::factor],yy_o[::factor],direction_o[::factor,1]-xx_o[::factor],-direction_o[::factor,0]+yy_o[::factor], color='white', scale=1, scale_units='x')\n",
    "\n",
    "        # base_path = \"/home/chimy/projects/biyesheji/cloth-segmentation/service_without_ROS_test\"\n",
    "        # tstamp = datetime.now().strftime(\"%d_%m_%Y_%H:%M:%S\")\n",
    "        # tstamp_path = os.path.join(base_path, tstamp)\n",
    "        # os.makedirs(tstamp_path)\n",
    "\n",
    "        # fig.canvas.draw()\n",
    "        # w,h = fig.canvas.get_width_height()\n",
    "        # buf = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(h, w, 3)\n",
    "        # np.save(os.path.join(tstamp_path, \"plot_%s\" % tstamp), buf)\n",
    "        \n",
    "        # rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        # cv2.imwrite(os.path.join(tstamp_path, \"rgb_%s.png\" % tstamp), rgb)\n",
    "        # plt.savefig(os.path.join(tstamp_path, 'uncertainty_%s.png' % tstamp))\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDetector:\n",
    "    def __init__(self, detection_method, crop_dims, datapath):\n",
    "        self.detection_method = detection_method\n",
    "        self.datapath = datapath\n",
    "        self._init_model(crop_dims)\n",
    "        self.depth_im = None\n",
    "        self.rgb_im = None\n",
    "        print(\"finish init\")\n",
    "\n",
    "    def _init_model(self, crop_dims):\n",
    "        if self.detection_method == 'groundtruth':\n",
    "            self.crop_dims = crop_dims\n",
    "            self.model = GroundTruth(self.crop_dims)\n",
    "        elif self.detection_method == 'network':\n",
    "            self.crop_dims = crop_dims\n",
    "            grasp_angle_method = 'inneredge'\n",
    "            \n",
    "            # grasp_angle_method 表示程序在计算抓取角度时要使用的方法\n",
    "            # 如果 grasp_angle_method 为 'predict'，说明程序要使用的模型是用于预测抓取角度的模型，\n",
    "            # 因此 model_path 参数将被替换为 model_angle_path 参数，即程序将使用不同的模型。\n",
    "            # 否则，model_path 参数保持不变，程序将使用默认的模型。\n",
    "            # 因此，这行代码的作用是根据 grasp_angle_method 的值获取正确的模型路径，并将其保存在 model_path 变量中。\n",
    "            \n",
    "            model_path = \"/home/chimy/old_projects/cloth-segmentation-main/runspath/pretrained_weights\"\n",
    "            self.model = ClothEdgeModel(self.crop_dims, grasp_angle_method, model_path)\n",
    "\n",
    "    def detect_edge(self, i):\n",
    "        try:\n",
    "            rgb_im = Image.open(os.path.join(self.datapath, \"rgb_%d.png\" % i))\n",
    "            depth_im = np.load(os.path.join(self.datapath, \"%d_depth.npy\" % i))\n",
    "            max_d = np.nanmax(depth_im)\n",
    "            depth_im[np.isnan(depth_im)] = max_d\n",
    "            print(os.path.join(self.datapath, \"%d_depth.npy\" % i))\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found\")\n",
    "        except:\n",
    "            print(\"Failed to read file\")\n",
    "        \n",
    "        # Prevents NaN from causing errors in image processing\n",
    "        self.depth_im = np.nan_to_num(depth_im)\n",
    "        self.rgb_im = cv2.imread(os.path.join(self.datapath, \"rgb_%d.png\" % i))\n",
    "\n",
    "        # _server_cb content\n",
    "        print(\"Received cloth detection request\")\n",
    "\n",
    "        rgb_im = deepcopy(self.rgb_im)  \n",
    "        depth_im = deepcopy(self.depth_im)\n",
    "\n",
    "        # plt.figure(dpi=300)\n",
    "        # plt.subplot(121)\n",
    "        # plt.title(\"rgb_im\")\n",
    "        # plt.imshow(rgb_im)\n",
    "        # plt.axis(\"off\")\n",
    "        # plt.subplot(122)\n",
    "        # plt.title(\"depth_im\")\n",
    "        # plt.imshow(depth_im)\n",
    "        # plt.axis(\"off\")\n",
    "        # plt.show()\n",
    "\n",
    "        response = DetectEdgeResponse()\n",
    "        response.rgb_im = self.rgb_im\n",
    "        response.depth_im = self.depth_im\n",
    "        # get response and save images\n",
    "        if self.detection_method == 'groundtruth':\n",
    "            pred = self.model.predict(rgb_im)\n",
    "            # pred = self.model.predict(rgb_im)\n",
    "            response.prediction = pred\n",
    "        elif self.detection_method == 'network':\n",
    "            self.model.update() # Check if model needs to be reloaded\n",
    "            print(\"depth_image.shape: \", depth_im.shape)\n",
    "            # all numpy.ndarray\n",
    "            corners, outer_edges, inner_edges, pred = self.model.predict(depth_im)\n",
    "            print(\"add time later\")\n",
    "            print(\"corners.shape:\", corners.shape)\n",
    "            print(\"outer_edges.shape:\", outer_edges.shape)\n",
    "            print(\"inner_edges.shape:\",inner_edges.shape)\n",
    "            print(\"pred.shape:\",pred.shape)\n",
    "\n",
    "            # save prediction \n",
    "            corners_img = get_depth_img(corners)\n",
    "            cv2.imwrite('corners_img.png', corners_img)\n",
    "            outer_img = get_depth_img(outer_edges)\n",
    "            cv2.imwrite('outer_img.png', outer_img)\n",
    "            inner_img = get_depth_img(inner_edges)\n",
    "            cv2.imwrite('inner_img.png', inner_img)\n",
    "            pred_img = get_depth_img(pred)\n",
    "            cv2.imwrite('pred_img.png', pred_img)\n",
    "\n",
    "        response.prediction = pred\n",
    "        response.corners = corners\n",
    "        response.outer_edges = outer_edges\n",
    "        response.inner_edges = inner_edges\n",
    "        \n",
    "        # TYPE_TEST = True\n",
    "        # if TYPE_TEST:\n",
    "        #     print(\"response.prediction.type:\",response.prediction.type)\n",
    "        #     print(\"response.corners.type:\",response.corners.type)\n",
    "        #     print(\"response.outer_edges.type:\",response.outer_edges.type)\n",
    "        #     print(\"response.inner_edges.type:\",response.inner_edges.type)\n",
    "        return response\n",
    "\n",
    "    def run(self, img_index):\n",
    "        # set self.depth_im & self.rgb_im, \n",
    "        # img_index: dataset image index\n",
    "        index = img_index\n",
    "\n",
    "        # DetectEdgeResponse\n",
    "        prediction = self.detect_edge(index)\n",
    "        \n",
    "        return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraspSelector:\n",
    "    def __init__(self, detection_method, grasp_point_method, grasp_angle_method, img_prediction, grasp_target):\n",
    "        self.detection_method = detection_method\n",
    "        self.grasp_point_method = grasp_point_method\n",
    "        self.grasp_angle_method = grasp_angle_method\n",
    "        self.img_prediction = img_prediction\n",
    "        self.grasp_target = grasp_target\n",
    "        self._init_selector()\n",
    "\n",
    "    def _init_selector(self):\n",
    "        # self.selector = XXX\n",
    "        if self.detection_method == 'groundtruth':\n",
    "            print(\"Not define GroundTruthSelector\")\n",
    "            # self.selector = GroundTruthSelector()\n",
    "        elif self.detection_method == 'network':\n",
    "            self.selector = NetworkGraspSelector(self.grasp_point_method, self.grasp_angle_method, self.grasp_target)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        print(\"Success init selector.\")\n",
    "        return\n",
    "    \n",
    "    def run(self):\n",
    "        img_prediction = self.img_prediction\n",
    "        inner_py = None\n",
    "        inner_px = None\n",
    "\n",
    "        if self.detection_method == 'groundtruth':\n",
    "            pred = deepcopy(img_prediction.prediction)\n",
    "            py, px, angle, inner_py, inner_px, var, angle_x, angle_y = self.selector.select_grasp(pred)\n",
    "        elif self.detection_method == 'network':\n",
    "            corners = deepcopy(img_prediction.corners)\n",
    "            outer_edges = deepcopy(img_prediction.outer_edges)\n",
    "            inner_edges = deepcopy(img_prediction.inner_edges)\n",
    "            rgb = deepcopy(img_prediction.rgb_im)\n",
    "            pred = deepcopy(img_prediction.prediction)\n",
    "            py, px, angle, inner_py, inner_px = self.selector.select_grasp(rgb, corners, outer_edges, inner_edges, pred)\n",
    "        else:\n",
    "            prediction = deepcopy(img_prediction.prediction)\n",
    "            py, px, angle = self.selector.select_grasp(prediction)\n",
    "            print(py, px, angle)\n",
    "\n",
    "        response = SelectGraspResponse()\n",
    "        response.py = py\n",
    "        response.px = px\n",
    "        response.angle = angle\n",
    "        # print inner_px & inner_py\n",
    "        if inner_py != None and inner_px != None:\n",
    "            response.inner_py = inner_py\n",
    "            response.inner_px = inner_px\n",
    "        if self.detection_method == 'groundtruth' and px != 0:\n",
    "            response.var = var.flatten()\n",
    "            response.angle_x = angle_x.flatten()\n",
    "            response.angle_y = angle_y.flatten()\n",
    "\n",
    "        print(\"Get grasp selection response\")\n",
    "        print('{:<10} {:<5} {:<10} {:<5}'.format(\"px:\", px, \"py:\", py))\n",
    "        print('{:<10} {} '.format(\"angle:\", angle))\n",
    "        print('\\033[32m' + str(angle) + '\\033[0m')\n",
    "        print('{:<10} {:<5} {:<10} {:<5}'.format(\"inner_px:\", inner_px, \"inner_py:\", inner_py))\n",
    "\n",
    "        # self.selector.plot(pred, px, py, var, None, inner_px, inner_py, prediction.prediction)\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m==========================================\u001b[0m\n",
      "\u001b[32mBegin detect_edge process\u001b[0m\n",
      "finish init\n",
      "/home/chimy/projects/biyesheji/data_painted_towel/0_depth.npy\n",
      "Received cloth detection request\n",
      "depth_image.shape:  (255, 243)\n",
      "In model.predict process, at first, image.shape:  (255, 243)\n",
      "In model.predict process, after crop, image.shape:  (255, 243)\n",
      "add time later\n",
      "corners.shape: (255, 243)\n",
      "outer_edges.shape: (255, 243)\n",
      "inner_edges.shape: (255, 243)\n",
      "pred.shape: (255, 243, 3)\n",
      "\u001b[32mEnd detect_edge process\u001b[0m\n",
      "\u001b[32m==========================================\u001b[0m\n",
      "prediction.rgb_im.shape:  (255, 243, 3)\n",
      "prediction.depth_im.shape: (255, 243)\n",
      "prediction.prediction.shape: (255, 243, 3)\n",
      "prediction.corners.shape: (255, 243)\n",
      "prediction.outer_edges.shape: (255, 243)\n",
      "prediction.inner_edges.shape: (255, 243)\n",
      "\u001b[32m==========================================\u001b[0m\n",
      "\u001b[32mBegin select_grasp process\u001b[0m\n",
      "Success init selector.\n",
      "Grasp point method: policy . Choose pixel x: 76 y: 120\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1037/3929630746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[32m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Begin select_grasp process'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraspSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrasp_point_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrasp_angle_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrasp_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgrasp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[32m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'End select_grasp process'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[32m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'=========================================='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1037/1394601436.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_px\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_grasp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouter_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1037/3374282858.py\u001b[0m in \u001b[0;36mselect_grasp\u001b[0;34m(self, rgb, corners, outer_edges, inner_edges, pred, retries, num_neighbour)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0minner_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcenter_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# count the angle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    detection_method = 'network'\n",
    "    datapath = \"/home/chimy/projects/biyesheji/data_painted_towel\"\n",
    "    crop_dims = [180, 650, 450, 900, 2] # seems not used yet\n",
    "    img_index = 0\n",
    "\n",
    "    print('\\033[32m' + '==========================================' + '\\033[0m')\n",
    "    print('\\033[32m' + 'Begin detect_edge process' + '\\033[0m')\n",
    "    e = EdgeDetector(detection_method, crop_dims, datapath)\n",
    "    prediction = e.run(img_index)\n",
    "    print('\\033[32m' + 'End detect_edge process' + '\\033[0m')\n",
    "    print('\\033[32m' + '==========================================' + '\\033[0m')\n",
    "\n",
    "    # print prediction shape \n",
    "    ENBALE_PREDICTION_SHAPE_TEST = True\n",
    "    if ENBALE_PREDICTION_SHAPE_TEST:\n",
    "        print('{:<25} {}'.format(\"prediction.rgb_im.shape:\", prediction.rgb_im.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.depth_im.shape:\", prediction.depth_im.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.prediction.shape:\", prediction.prediction.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.corners.shape:\", prediction.corners.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.outer_edges.shape:\", prediction.outer_edges.shape))\n",
    "        print('{:<25} {}'.format(\"prediction.inner_edges.shape:\", prediction.inner_edges.shape))\n",
    "\n",
    "    detection_method = \"network\"\n",
    "    grasp_point_method = \"policy\"\n",
    "    # Option: predict, inneredge, center\n",
    "    grasp_angle_method = \"predict\"\n",
    "    # grasp_target = \"edge\"\n",
    "    grasp_target = \"corner\"\n",
    "\n",
    "    print('\\033[32m' + '==========================================' + '\\033[0m')\n",
    "    print('\\033[32m' + 'Begin select_grasp process' + '\\033[0m')\n",
    "    g = GraspSelector(detection_method, grasp_point_method, grasp_angle_method, prediction, grasp_target)\n",
    "    grasp = g.run()\n",
    "    print('\\033[32m' + 'End select_grasp process' + '\\033[0m')\n",
    "    print('\\033[32m' + '==========================================' + '\\033[0m')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "towel37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
